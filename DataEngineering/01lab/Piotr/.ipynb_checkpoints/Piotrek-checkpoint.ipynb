{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: numpy==1.24.2 in /home/piotrek/.local/lib/python3.10/site-packages (1.24.2)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pandas==1.5.3 in /home/piotrek/.local/lib/python3.10/site-packages (1.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/piotrek/.local/lib/python3.10/site-packages (from pandas==1.5.3) (1.24.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/piotrek/.local/lib/python3.10/site-packages (from pandas==1.5.3) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas==1.5.3) (2022.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: tabulate==0.9.0 in /home/piotrek/.local/lib/python3.10/site-packages (0.9.0)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: numpy==1.24.2 in /home/piotrek/.local/lib/python3.10/site-packages (1.24.2)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pandas==1.5.3 in /home/piotrek/.local/lib/python3.10/site-packages (1.5.3)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas==1.5.3) (2022.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/piotrek/.local/lib/python3.10/site-packages (from pandas==1.5.3) (2.8.2)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/piotrek/.local/lib/python3.10/site-packages (from pandas==1.5.3) (1.24.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: tabulate==0.9.0 in /home/piotrek/.local/lib/python3.10/site-packages (0.9.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.2\n",
    "!pip install pandas==1.5.3\n",
    "!pip install tabulate==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('lab1_ex01.csv', sep=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fileproj1_ex01.csvis a properly formed CSV file, with fields separated using commas (,) andwith column headers. Load it into a DataFrame.Create a file calledex01_fields.json, which contains informationallof the columns in the fileyou read. The file should contain an array of dictionaries with the following items:•column name (key:name),•percentage of missing values (key:missing, values in the range[0.0, 1.0]),•data type as a string with the following values (key:type:–intfor integer types,–floatfor floating-point types,–otherfor all other types.\n",
    "\n",
    "\n",
    "def prepare_json_from_dataframe(df, filename):\n",
    "    columns = []\n",
    "    for col in df.columns:\n",
    "        col_info = {}\n",
    "        col_info[\"name\"] = col\n",
    "        col_info[\"missing\"] = df[col].isnull().sum() / len(df)\n",
    "\n",
    "        if df[col].dtype == \"int\":\n",
    "            col_info[\"type\"] = \"int\"\n",
    "        elif df[col].dtype == \"float\":\n",
    "            col_info[\"type\"] = \"float\"\n",
    "        else:\n",
    "            col_info[\"type\"] = \"other\"\n",
    "\n",
    "        columns.append(col_info)\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(columns, outfile)\n",
    "\n",
    "prepare_json_from_dataframe(df, \"ex01_fields.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Compute statistics for all columns in your dataframe.For numeric columns include:•the count of non-empty values (count),2 •the average (mean),•the standard deviation (std),•the minimum (min) and maximum (max) values,•the the 25th, 50th, and 75th percentiles (attribute names:25%,50%and75%, respectively).For non-numeric columns include:•the count of non-empty values (count),•the number of unique values (unique),•the most common value (top) and its frequency (number of occurences;freq).Save the result to a JSON file calledex02_stats.jsonwhich contains a dictionary at the top level;the keys in the dictionary are column names, and the values are dictionaries with keys as describedabove\n",
    "\n",
    "def prepare_detailed_json_from_dataframe(dt, filename):\n",
    "    stats_df = df.describe(include=\"all\") # Compute summary statistics for all columns\n",
    "    stats_df = stats_df.dropna(axis=1, how=\"all\") # Remove columns with all null values\n",
    "    df_dict = stats_df.to_dict() # Convert to dictionary\n",
    "    for column in df_dict:\n",
    "        df_dict[column] = {key: value for key, value in df_dict[column].items() if not pd.isnull(value)} # Remove null values from dictionary\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(df_dict, outfile)\n",
    "\n",
    "prepare_detailed_json_from_dataframe(df, \"ex02_stats.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Rename (“normalize”) the columns in the dataframe, so that they (sort of) follow thePEP 8guidelines forvariable names.Apply the following rules:•keep only characters which belong to the[A-Za-z0-9_ ]class (capital and small letters,digits, underscore and space),•convert all letters to lowercase,•replace all spaces with underscores (_).Make the changes in your DataFrame persistent.\n",
    "\n",
    "for col in df.columns:\n",
    "    new_col = re.sub(r\"[^A-Za-z0-9_ ]\", \"\", col)\n",
    "    new_col = new_col.lower()\n",
    "    new_col = new_col.replace(\" \", \"_\")\n",
    "    df.rename(columns={col: new_col}, inplace=True)\n",
    "\n",
    "df.to_csv(\"ex03_columns.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Create a JSON file called ex04_json.json, which contains an array of rows stored as dictionaries,each with the DataFrame columns as keys (and values as values, obviously)\n",
    "df.to_json(\"ex04_json.json\", orient=\"records\")\n",
    "\n",
    "#Create an MS Excel file called ex04_excel.xlsx, which contains the column headers, but not the index values.\n",
    "df.to_excel(\"ex04_excel.xlsx\", index=False)\n",
    "\n",
    "#Create a pickle file called ex04_pickle.pkl with the DataFrame.\n",
    "df.to_pickle(\"ex04_pickle.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import tabulate\n",
    "#Load the DataFrame pickled in file lab1_ex05.pkl.Select the following items from the DataFrame:•the 2nd and 3rd columns (regardless of their names),•rows whose index values begin with the letter v.\n",
    "\n",
    "ex05_df = pd.read_pickle(\"lab1_ex05.pkl\")\n",
    "\n",
    "result = ex05_df.iloc[:,[1,2]]\n",
    "starts_with_v = result.index.str.startswith(\"v\")\n",
    "result = result[starts_with_v]\n",
    "\n",
    "# Save the result to a Markdown table stored in file ex05_table.md. Include the result, but don’t put anything in cells with missing values (i.e. prevent nan from being printed there).\n",
    "with open(\"ex05_table.md\", 'w') as outfile:\n",
    "    outfile.write(tabulate.tabulate(result.fillna(\"\"), headers='keys', tablefmt='pipe', showindex=True, missingval=\"\"))\n",
    "\n",
    "# fillna(\"\") is used to replace NaN with empty string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Pandas DataFrames are two-dimensional structures. However, data in JSON files often has ahierarchical structure, e.g. objects (dictionaries) are nested within objects.Filelab1_ex06.jsoncontains an array with such hierarchical objects (the structure of each arrayelement is the same).Using the data in the file, create a Pandas DataFrame, which contains a flattened version of thedata. For nested dictionaries, the column names should have the keys separated using dots (.).\n",
    "\n",
    "ex06_df = pd.read_json(\"lab1_ex06.json\")\n",
    "ex06_df = pd.json_normalize(ex06_df.to_dict(orient=\"records\"))\n",
    "\n",
    "ex06_df.to_pickle(\"ex06_pickle.pkl\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
